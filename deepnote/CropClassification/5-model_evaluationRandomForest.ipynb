{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "41903ef8",
        "execution_start": 1765279355321,
        "execution_millis": 1682,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "70589a96279247dfbe518683fcda5c36",
        "deepnote_cell_type": "code"
      },
      "source": "import numpy as np\nimport joblib\nimport json\nimport pandas as pd\nfrom sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_recall_fscore_support,\n    classification_report\n)\nfrom lime.lime_tabular import LimeTabularExplainer\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, classification_report, confusion_matrix\n)\nfrom sklearn.base import clone\nfrom sklearn.metrics import accuracy_score, f1_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n",
      "block_group": "70589a96279247dfbe518683fcda5c36",
      "execution_count": 1,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "d566614593fc4f478ee669acbcf886b0",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Chargement des donn√©es",
      "block_group": "5fb1ce895e064141bdfdf83b0b2bbfc8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "ee8a9393",
        "execution_start": 1765279357061,
        "execution_millis": 943,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "89a2f293815142f1898c7cf4eb45182f",
        "deepnote_cell_type": "code"
      },
      "source": "X_train = np.load('data/X_train_scaled.npy')\nX_test  = np.load('data/X_test_scaled.npy')\ny_train = np.load('data/y_train.npy')\ny_test  = np.load('data/y_test.npy')\n\n# Encodage des labels\nle = joblib.load('models/label_encoder.pkl')\nclasses = le.classes_\nlen(classes), classes\n",
      "block_group": "56ff003be6de4e09983a3bc0dd6bcf21",
      "execution_count": 2,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "cdc535d9599f432299f0365e530cb3bc",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# HYPERPARAM TUNING",
      "block_group": "b0a8936f40904e85aeced1ea77ce85b5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "5da9267b",
        "execution_start": 1765279358051,
        "execution_millis": 0,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "6b3da0ef85b647869a9b0525b0382d04",
        "deepnote_cell_type": "code"
      },
      "source": "rf_base = RandomForestClassifier(\n    random_state=42,\n    n_jobs=-1\n)\n\nparam_dist = {\n    'n_estimators': [100, 200, 300, 500],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2', 0.5],\n}",
      "block_group": "f64b5409a9a14ee79b2859e03c6f389d",
      "execution_count": 3,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "80c41580149d4cb3baee42901137ed4e",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Meilleur mod√®le RF + m√©triques sur le test",
      "block_group": "8c860fad9f91452091720f881670a1b1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "ea2d25a2",
        "execution_start": 1765279358111,
        "execution_millis": 253,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "63cef55a78004d2eb7b9d577185e34e5",
        "deepnote_cell_type": "code"
      },
      "source": "best_rf = RandomForestClassifier(\n    n_estimators=300,      # üëâ remplace par ta meilleure valeur\n    max_depth=20,         # üëâ idem\n    min_samples_split=2,\n    min_samples_leaf=1,\n    max_features='sqrt',\n    random_state=42,\n    n_jobs=-1\n)\n\n# Entra√Ænement sur tout le jeu d'entra√Ænement\nbest_rf.fit(X_train, y_train)\ny_pred_test = best_rf.predict(X_test)\ntest_accuracy = accuracy_score(y_test, y_pred_test)\ntest_f1_macro = f1_score(y_test, y_pred_test, average=\"macro\")\n\nprint(\"\\nEVALUATION DU MODELE RANDOM FOREST\")\nprint(\"=\" * 60)\nprint(f\"Test Accuracy        : {test_accuracy:.4f}\")\nprint(f\"F1_macro (test)      : {test_f1_macro:.4f}\")\nprint(f\"Nombre de classes    : {len(classes)}\")\nprint(f\"Classes              : {classes}\")\n",
      "block_group": "a7361b7f5784498bb7695898924a1399",
      "execution_count": 4,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "bf02e601004748a58ac55969da06f080",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Classification report + matrice de confusion",
      "block_group": "f313a54ce2fb415ab33d552ddc0ee048"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "e7fd224e",
        "execution_start": 1765279358411,
        "execution_millis": 0,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "63c908a1701f40039c3bc968bde4ad9d",
        "deepnote_cell_type": "code"
      },
      "source": "print(\"\\nClassification report :\")\nprint(classification_report(y_test, y_pred_test, target_names=classes))",
      "block_group": "cc6595be20084cf7b263487034297fe7",
      "execution_count": 5,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "3076144e",
        "execution_start": 1765279358461,
        "execution_millis": 543,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "205e7618d47c47a5bbbdb889e92cb466",
        "deepnote_cell_type": "code"
      },
      "source": "plt.figure(figsize=(12, 10))\ncm = confusion_matrix(y_test, y_pred_test)\nsns.heatmap(\n    cm,\n    annot=True,        # ‚Üê affiche les valeurs\n    fmt=\"d\",           # ‚Üê format entier (pas float)\n    cmap=\"Blues\",\n    cbar=True\n)\n\nplt.title(\"Matrice de confusion ‚Äì Random Forest\")\nplt.xlabel(\"Pr√©dictions\")\nplt.ylabel(\"V√©rit√©s\")\nplt.tight_layout()\nplt.show()",
      "block_group": "da1b424bbb0441728185285f921ec867",
      "execution_count": 6,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "d9afa62933b74656931d9a8d3cb00e1f",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# M√©triques d√©taill√©es:",
      "block_group": "7f83a1564d8d433ea88e16988a1d09b5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "93163121",
        "execution_start": 1765279359051,
        "execution_millis": 1,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "761faf97d2f24c53beb6a07a556de803",
        "deepnote_cell_type": "code"
      },
      "source": "accuracy    = accuracy_score(y_test, y_pred_test)\nmacro_f1    = f1_score(y_test, y_pred_test, average=\"macro\")\nweighted_f1 = f1_score(y_test, y_pred_test, average=\"weighted\")\n\nprint(\"=== M√©triques globales (Random Forest) ===\")\nprint(f\"Accuracy globale      : {accuracy:.4f}\")\nprint(f\"F1-macro              : {macro_f1:.4f}\")\nprint(f\"F1-pond√©r√© (weighted) : {weighted_f1:.4f}\")\n\n\n# ==== M√©triques par classe ====\nprecision, recall, f1, support = precision_recall_fscore_support(\n    y_test, \n    y_pred_test, \n    labels=np.arange(len(classes)),\n    zero_division=0\n)\n\n# noms demand√©s\nmetrics_names = ['Precision', 'Recall', 'F1-Score', 'Test Accuracy']\n\n# ==== Tableau d√©taill√© ====\nmetrics_df = pd.DataFrame({\n    \"Classe\": classes,\n    \"Support\": support,\n    \"Precision\": precision,\n    \"Recall\": recall,\n    \"F1-Score\": f1,\n})\n\n# Ajouter la Test Accuracy globale (identique √† chaque ligne)\nmetrics_df[\"Test Accuracy\"] = accuracy\n\nprint(\"\\n=== M√©triques d√©taill√©es par classe ===\")\ndisplay(metrics_df.round(3))\n\n\n# ==== Rapport sklearn ====\nprint(\"\\n=== Rapport de classification (sklearn) ===\")\nprint(classification_report(\n    y_test, \n    y_pred_test, \n    target_names=classes, \n    zero_division=0\n))",
      "block_group": "e966cb26fcb443ef96d8cd0267f8143e",
      "execution_count": 7,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "adf347accc144fd09d292087d9c7a7c0",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Visualisation des m√©triques",
      "block_group": "ab7687c36f9a43f2a8ea9e8d121745e8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "1a87f75a",
        "execution_start": 1765279359101,
        "execution_millis": 73,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "6248fb6dc5f24749aa82d15b01f7aaad",
        "deepnote_cell_type": "code"
      },
      "source": "from sklearn.metrics import precision_score, recall_score\nimport matplotlib.pyplot as plt\n\n# === M√©triques globales (pond√©r√©es) ===\nprecision_weighted = precision_score(y_test, y_pred_test, average=\"weighted\")\nrecall_weighted    = recall_score(y_test, y_pred_test, average=\"weighted\")\nf1_global          = weighted_f1      # tu peux mettre macro_f1 si tu pr√©f√®res\ntest_acc           = accuracy\n\nmodel_name = \"Random Forest\"\n\n# === Figure 2x2 comme dans ta capture ===\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\n\n# --- 1) Precision ---\nax = axes[0, 0]\nax.barh([model_name], [precision_weighted], color=\"#F08080\")\nax.set_xlim(0, 1)\nax.set_xlabel(\"Precision\")\nax.set_title(f\"Precision : {precision_weighted:.4f}\")\nax.text(precision_weighted, 0, f\"{precision_weighted:.4f}\", va=\"center\", ha=\"left\")\n\n# --- 2) Recall ---\nax = axes[0, 1]\nax.barh([model_name], [recall_weighted], color=\"#90EE90\")\nax.set_xlim(0, 1)\nax.set_xlabel(\"Recall\")\nax.set_title(f\"Recall: {recall_weighted:.4f}\")\nax.text(recall_weighted, 0, f\"{recall_weighted:.4f}\", va=\"center\", ha=\"left\")\n\n# --- 3) F1-Score ---\nax = axes[1, 0]\nax.barh([model_name], [f1_global], color=\"#DDA0DD\")\nax.set_xlim(0, 1)\nax.set_xlabel(\"F1-Score\")\nax.set_title(f\"F1-Score : {f1_global:.4f}\")\nax.text(f1_global, 0, f\"{f1_global:.4f}\", va=\"center\", ha=\"left\")\n\n# --- 4) Test Accuracy ---\nax = axes[1, 1]\nax.barh([model_name], [test_acc], color=\"#87CEFA\")\nax.set_xlim(0, 1)\nax.set_xlabel(\"Test Accuracy\")\nax.set_title(f\"Test Accuracy: {test_acc:.4f}\")\nax.text(test_acc, 0, f\"{test_acc:.4f}\", va=\"center\", ha=\"left\")\n\nplt.tight_layout()\nplt.show()\n",
      "block_group": "c0fde9c675814039bf0635e42693bb80",
      "execution_count": 8,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "2c4e6d7f5cfb444baabfef3bc0c014fd",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Barplot F1-score par classe",
      "block_group": "bc653114b0a44addbfdf010cd89929bf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "604c5469",
        "execution_start": 1765279359221,
        "execution_millis": 83,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "37073c7f21034173bee2b7cb20e52e14",
        "deepnote_cell_type": "code"
      },
      "source": "metrics_sorted = metrics_df.sort_values(\"F1-Score\", ascending=False)\n\nplt.figure(figsize=(12, 7))\n\n# Palette nuance de vert\ncolors = sns.color_palette(\"Greens\", n_colors=len(metrics_sorted))\n\n# Barplot horizontal\nplt.barh(metrics_sorted[\"Classe\"], metrics_sorted[\"F1-Score\"], color=colors)\n\nplt.xlim(0, 1)\nplt.title(\"F1-Score par classe ‚Äì Random Forest\")\nplt.xlabel(\"F1-Score\")\nplt.ylabel(\"Classe\")\nplt.tight_layout()\nplt.show()\n\n",
      "block_group": "5158c90b9aaa4dbcb40a33975e62f26b",
      "execution_count": 9,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "4a01b62cb1924e1dbdce2053a19c130a",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Vraie courbe d‚Äôoverfitting",
      "block_group": "b9708575ee544986883cbf23981540c5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "9deb3683",
        "execution_start": 1765279359351,
        "execution_millis": 2654,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "213c1bb56fad4b3da83972a4d234e2dd",
        "deepnote_cell_type": "code"
      },
      "source": "train_sizes_frac = np.linspace(0.1, 1.0, 10)\n\ntrain_scores = []\ntest_scores  = []\n\nfor frac in train_sizes_frac:\n    n_samples = int(len(X_train) * frac)\n    X_sub = X_train[:n_samples]\n    y_sub = y_train[:n_samples]\n\n    model_clone = clone(best_rf)\n    model_clone.fit(X_sub, y_sub)\n\n    y_pred_train = model_clone.predict(X_sub)\n    y_pred_test  = model_clone.predict(X_test)\n\n    train_scores.append(accuracy_score(y_sub, y_pred_train))\n    test_scores.append(accuracy_score(y_test, y_pred_test))\n\ntrain_scores = np.array(train_scores)\ntest_scores  = np.array(test_scores)\n\ntrain_errors = 1 - train_scores\ntest_errors  = 1 - test_scores\n\nx = train_sizes_frac * 100\nidx_opt = np.argmin(test_errors)\nx_opt = x[idx_opt]\ny_max = max(train_errors.max(), test_errors.max())\n\nplt.figure(figsize=(8, 5))\nplt.plot(x, train_errors, marker=\"o\", linewidth=2, label=\"Training error\")\nplt.plot(x, test_errors, marker=\"o\", linewidth=2, label=\"Validation/Test error\")\n\nplt.axvline(x_opt, color=\"black\", linestyle=\"--\")\nplt.text(x_opt, y_max * 0.95, \"Good-fit\", ha=\"center\", va=\"bottom\")\n\n# Fl√®ches Under-fitting / Over-fitting\nplt.annotate(\n    \"Under-fitting\",\n    xy=(x.min()+5, y_max*0.88),\n    xytext=(x.min()+20, y_max*0.88),\n    arrowprops=dict(arrowstyle=\"<->\"),\n    ha=\"center\",\n    va=\"center\"\n)\nplt.annotate(\n    \"Over-fitting\",\n    xy=(x_opt+5, y_max*0.88),\n    xytext=(x.max()-10, y_max*0.88),\n    arrowprops=dict(arrowstyle=\"<->\"),\n    ha=\"center\",\n    va=\"center\"\n)\n\nplt.xlabel(\"Training set size (%)\")\nplt.ylabel(\"Error (1 - accuracy)\")\nplt.title(\"Under-fitting vs Over-fitting ‚Äì Random Forest\")\nplt.legend(loc=\"upper right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()",
      "block_group": "b232c1e70de04e429668df37d21f94b7",
      "execution_count": 10,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "dd36f16e1d6e4a4fbfc327b777085ef0",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Courbes ROC (One-vs-Rest)",
      "block_group": "5e4dde1f79044d1889a3a63c24a034f5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "bb29b9f3",
        "execution_start": 1765279362051,
        "execution_millis": 354,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "e0721b0dbbac4f638fbc97e5ed909bc9",
        "deepnote_cell_type": "code"
      },
      "source": "best_model = joblib.load(\"models/tuned/random_forest_best_only_eval.pkl\")\n# Nombre de classes\nn_classes = len(classes)\n\n# 1) Binarisation des labels pour le One-vs-Rest\n#   y_test_bin : matrice (nb_samples, n_classes) avec 0/1\ny_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n\n# 2) Probabilit√©s pr√©dites par le mod√®le sur le test\ny_score = best_model.predict_proba(X_test)   # shape : (nb_samples, n_classes)\n\n# 3) Courbes ROC et AUC par classe\nfpr = {}   # False Positive Rate\ntpr = {}   # True Positive Rate\nroc_auc = {}\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# 4) Micro-average ROC (toutes les classes \"aplatis\")\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n# 5) Affichage\nplt.figure(figsize=(10, 7))\n\n# Courbe micro-average (globale)\nplt.plot(\n    fpr[\"micro\"], tpr[\"micro\"],\n    label=f\"Micro-average (AUC = {roc_auc['micro']:.3f})\",\n    color=\"magenta\", linestyle=\"--\", linewidth=3\n)\n\n# Courbes par classe (option : beaucoup de classes ‚Üí alpha faible)\nfor i, cls_name in enumerate(classes):\n    plt.plot(\n        fpr[i], tpr[i],\n        lw=1, alpha=0.5,\n        label=f\"{cls_name} (AUC = {roc_auc[i]:.3f})\"\n    )\n\n# Diagonale \"mod√®le al√©atoire\"\nplt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curves ‚Äì One-vs-Rest\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n",
      "block_group": "a39402ea38e949288bc989d397f01ca4",
      "execution_count": 11,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "7f3d463016a54485858b8fcf6d8ce25e",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# AUC Scores",
      "block_group": "ab148bb635d4402fb941b06e3ac08565"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "887ff00f",
        "execution_start": 1765279362451,
        "execution_millis": 0,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "9613aa52d5054e5790eb5ba0a55ef56f",
        "deepnote_cell_type": "code"
      },
      "source": "# Tableau des AUC par classe\nauc_scores = pd.DataFrame({\n    \"Classe\": classes,\n    \"AUC\": [roc_auc[i] for i in range(n_classes)]\n})\n\n# Tri par AUC d√©croissante\nauc_scores = auc_scores.sort_values(\"AUC\", ascending=False).reset_index(drop=True)\n\n# Moyennes pour info\nmacro_auc = auc_scores[\"AUC\"].mean()\n\nprint(\"=== AUC par classe ===\")\ndisplay(auc_scores)\n\nprint(f\"\\nAUC moyenne (macro) : {macro_auc:.4f}\")\nprint(f\"AUC micro-average   : {roc_auc['micro']:.4f}\")\n",
      "block_group": "80827574471446798d923884fd5fe819",
      "execution_count": 12,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "59dad0603c1a48eb893371043cb4db06",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# AUC par classe (visualisation)",
      "block_group": "623c9038215349e0a95cbf866dc36cb1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "3616327f",
        "execution_start": 1765279362501,
        "execution_millis": 68,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "784423cd262542a4b6dcfcf5b6b43bfd",
        "deepnote_cell_type": "code"
      },
      "source": "auc_sorted = auc_scores.sort_values(\"AUC\", ascending=True)\n\nplt.figure(figsize=(10, 8))\n\n# Palette d√©grad√©e jaune ‚Üí vert (comme ton screen)\ncolors = sns.color_palette(\"YlGn\", n_colors=len(auc_sorted))\n\nplt.barh(\n    auc_sorted[\"Classe\"],\n    auc_sorted[\"AUC\"],\n    color=colors,\n    edgecolor=\"black\"\n)\n\nplt.xlim(0.0, 1.0)\nplt.xlabel(\"AUC Score\")\nplt.ylabel(\"Crop Class\")\nplt.title(\"AUC Score per Class ‚Äì \" + (\"Random Forest\" if hasattr(best_model, 'n_estimators') else \"Naive Bayes\"))\n\n# Afficher la valeur AUC au bout de chaque barre\nfor i, v in enumerate(auc_sorted[\"AUC\"]):\n    plt.text(v + 0.005, i, f\"{v:.3f}\", va=\"center\")\n\nplt.tight_layout()\nplt.show()",
      "block_group": "51f26c419d45431684be4b45defa7af5",
      "execution_count": 13,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "f6b1467c80654130a1b21a432174f371",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Sauvegarder le mod√®le RF + infos",
      "block_group": "112aedf7fc774e84b8760aab4c73045e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "cf72c864",
        "execution_start": 1765279362621,
        "execution_millis": 647,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "ed36f85bbf7e4ed28ecdbb5b81cdc1d2",
        "deepnote_cell_type": "code"
      },
      "source": "rf_model_path = \"models/tuned/random_forest_best_only_eval.pkl\"\njoblib.dump(best_rf, rf_model_path)\n\n# Sauvegarde des infos dans un json\nbest_rf_info = {\n    \"model_name\": \"Random Forest\",\n    \"model_path\": rf_model_path,\n    \"test_accuracy\": float(test_accuracy),\n    \"test_f1_macro\": float(test_f1_macro),\n    \"n_classes\": len(classes),\n    \"classes\": list(classes)\n}\n\nwith open(\"results/tuning/best_rf_info.json\", \"w\") as f:\n    json.dump(best_rf_info, f, indent=4)\n\nbest_rf_info",
      "block_group": "fa6a489867a541898950fd221ae90dd5",
      "execution_count": 14,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "e3690d36f9da48d19c4981baf45ff4e8",
        "deepnote_cell_type": "text-cell-h1"
      },
      "source": "# Xai_lime",
      "block_group": "909256bd76c845c0a04a33132af85815"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "1304bcdd",
        "execution_start": 1765279363311,
        "execution_millis": 370,
        "execution_context_id": "27fb5944-8a8a-43a6-8737-2300a15135ac",
        "cell_id": "a433b102552c4c718faf0fc36fb12e48",
        "deepnote_cell_type": "code"
      },
      "source": "X_train_arr = np.array(X_train)\nX_test_arr  = np.array(X_test)\n\n# 2) Noms des features\ntry:\n    feature_names\n    print(\"‚úÖ feature_names d√©j√† d√©fini, utilisation des noms existants.\")\nexcept NameError:\n    feature_names = [f\"feature_{i}\" for i in range(X_train_arr.shape[1])]\n    print(\"‚ÑπÔ∏è feature_names n'√©tait pas d√©fini : cr√©ation de noms g√©n√©riques.\")\n\n# 3) Cr√©ation de l‚Äôexplainer LIME\nexplainer = LimeTabularExplainer(\n    X_train_arr,\n    feature_names=feature_names,\n    class_names=list(classes),\n    mode=\"classification\",\n    discretize_continuous=True\n)\n\n# 4) Choix de l‚Äôinstance √† expliquer\nidx = 10  # tu peux changer l‚Äôindex\ninstance = X_test_arr[idx]\ntrue_label_idx  = int(y_test[idx])\ntrue_label_name = classes[true_label_idx]\n\nprint(f\"üîç Instance test n¬∞{idx}\")\nprint(f\"   Vraie classe : {true_label_name} (index {true_label_idx})\")\n\n# 5) On r√©cup√®re d'abord la classe pr√©dite par le Random Forest\npred_label_idx  = int(best_rf.predict(instance.reshape(1, -1))[0])\npred_label_name = classes[pred_label_idx]\nprint(f\"   Classe pr√©dite : {pred_label_name} (index {pred_label_idx})\")\n\n# 6) Explication LIME pour CE label pr√©cis\nexp = explainer.explain_instance(\n    instance,\n    best_rf.predict_proba,   # LIME appelle le mod√®le en proba\n    num_features=10,         # top 10 features les plus importantes\n    labels=[pred_label_idx]  # on demande le label pr√©dict√©, pas \"1\" par d√©faut\n)\n\n# 7) Affichage graphique pour ce label\nfig = exp.as_pyplot_figure(label=pred_label_idx)\nplt.title(f\"Explication LIME ‚Äì Random Forest ‚Äì Instance {idx}\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n# 8) Vue d√©taill√©e dans le notebook (table + contributions)\nexp.show_in_notebook(show_table=True)",
      "block_group": "e770d71b88774f21a461fa6c4d585a6c",
      "execution_count": 15,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=37cd5642-eb00-4cb1-969e-a9bc85cf5e83' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "4bb31aa8e8fa44b3b8385f4b6301fa06"
  }
}